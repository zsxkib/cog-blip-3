# Configuration for Cog ⚙️
# Reference: https://cog.run/yaml

build:
  # set to true if your model requires a GPU
  gpu: true
  cuda: "12.1"

  # a list of ubuntu apt packages to install
  system_packages:
    - "libgl1-mesa-glx"
    - "libglib2.0-0"

  # python version in the form '3.11' or '3.11.4'
  python_version: "3.10"

  # a list of packages in the format <package-name>==<version>
  python_packages:
    - "torch>=2.2.1"
    - "torchvision>=0.17.1"
    - "torchaudio>=2.2.1"
    - "open_clip_torch==2.24.0"
    - "einops"
    - "einops-exts"
    - "pillow"

    # To use the development version (4.41.0.dev0) of the transformers library as of 05/07/2024, execute:
    - "git+https://github.com/huggingface/transformers@2d1602a" 
  # commands run after the environment is setup
  run:
    - curl -o /usr/local/bin/pget -L "https://github.com/replicate/pget/releases/download/v0.8.1/pget_linux_x86_64" && chmod +x /usr/local/bin/pget

# predict.py defines how predictions are run on your model
predict: "predict.py:Predictor"
